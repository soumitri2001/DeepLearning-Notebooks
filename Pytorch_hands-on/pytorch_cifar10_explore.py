# -*- coding: utf-8 -*-
"""pytorch_for_noob_part 3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cWq3AgN6dLuxHg_dzhCnYV4HQxezcCH9
"""

# cnn model trained on CIFAR-10 dataset

import matplotlib.pyplot as plt
import numpy as np

import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import Dataset,DataLoader

import torch.nn.functional as F

# transformations
composed = transforms.Compose([
                         transforms.ToTensor(),
                         transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))
                        ])

# CIFAR-10 dataset
train_data = torchvision.datasets.CIFAR10(root='./data',train=True,
                                          download=True,transform=composed)

test_data = torchvision.datasets.CIFAR10(root='./data',train=False,
                                         download=True,transform=composed)

# hyperparameters
batch_size = 4
num_epochs = 10
learning_rate = 0.01

# device
device = None
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    device = torch.device('cpu')

print(device)

# DataLoaders

train_loader = DataLoader(dataset=train_data,
                          batch_size=batch_size,
                          shuffle=True,
                          num_workers=2)

test_loader = DataLoader(dataset=test_data,
                         batch_size=batch_size,
                         shuffle=False,
                         num_workers=2)

len(train_loader),len(test_loader)

# label classes
classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

num_classes = len(classes)
print(num_classes)

# model class
class ConvNet(nn.Module):
    def __init__(self,num_classes):
        super(ConvNet,self).__init__()
        
        # cnn layers
        self.conv1 = nn.Conv2d(in_channels=3,out_channels=6,kernel_size=5)
        self.pool = nn.MaxPool2d(kernel_size=2,stride=2)
        self.conv2 = nn.Conv2d(in_channels=6,out_channels=16,kernel_size=5)
        
        #fc layers
        self.linear1 = nn.Linear(in_features=16*5*5,out_features=120)
        self.linear2 = nn.Linear(in_features=120,out_features=84)
        self.linear3 = nn.Linear(in_features=84,out_features=num_classes)

    def forward(self,x):
        x1 = self.pool(F.relu(self.conv1(x)))
        x2 = self.pool(F.relu(self.conv2(x1)))
        x2_flat = x2.view(-1,16*5*5) # Flatten
        x3 = F.relu(self.linear1(x2_flat))
        x4 = F.relu(self.linear2(x3))
        x5 = F.relu(self.linear3(x4))
        return x5

# model defining
model = ConvNet(num_classes)
model = model.to(device)

# loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)

n_total_steps = len(train_loader)

# training loop
for epoch in range(num_epochs):
    for ii,(images,labels) in enumerate(train_loader):
        # original shape = [4,3,32,32] : 4 := batch_size, 3 := RGB, dims =32x32
        # input_layer = 3 input_channels, 6 output_channels, 5 kernel_size
        images = images.to(device)
        labels = labels.to(device)

        # forward
        outputs = model(images)
        loss = criterion(outputs,labels)

        # backward and updates
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()

        if (ii+1)%2000 == 0:
            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{ii+1}/{n_total_steps}], Loss = {loss.item():.6f}')

    print('----------------------------------------')

# evaluating model

with torch.no_grad():
    # for entire test set
    n_correct = 0
    n_samples = 0

    # for each class label
    n_class_correct = [0 for i in range(num_classes)]
    n_class_samples = [0 for i in range(num_classes)]

    for images,labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)

        outputs = model(images)

        _,preds = torch.max(outputs,1)
        n_samples += labels.size(0)
        n_correct += (preds == labels).sum().item()

        # iterating over the batch 
        for i in range(batch_size):
            label = labels[i]
            pred = preds[i]
            n_class_samples[label] +=1
            if(label == pred):
                n_class_correct[label] += 1
            
    accuracy = n_correct/float(n_samples)
    print(f'Accuracy of model on test set = {accuracy:.4f}')
    
    print('-------------------------------------------')
    
    # printing accuracy per class
    for i in range(num_classes):
        accuracy = n_class_correct[i]/float(n_class_samples[i])
        print(f'Accuracy of {classes[i]} : {accuracy}')

# saving model
MODEL_PATH = 'model.pth'
torch.save(model.state_dict(),MODEL_PATH)

# printing parameters of the model

for param in model.parameters():
    print(param.shape)
    print(str(param))

