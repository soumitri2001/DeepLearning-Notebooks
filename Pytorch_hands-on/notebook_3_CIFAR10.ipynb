{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_for_noob_part 3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b0f1ce5483b346b5b337cbc41543a2a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b3dbf7ce28d84be491b4347e46d35bc7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_07d2ec5b2bf1434f84473648c3765bc4",
              "IPY_MODEL_1aee3aa0d8e9437c9226f22ee4a409cb"
            ]
          }
        },
        "b3dbf7ce28d84be491b4347e46d35bc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07d2ec5b2bf1434f84473648c3765bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bd9f4a4ba9ae45dfb880f3a0bdd57551",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dee018f1eaca498ebcaddea80d182a0c"
          }
        },
        "1aee3aa0d8e9437c9226f22ee4a409cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_91e7db48c0f046a0bfc72e695f99223e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:19&lt;00:00, 42241675.02it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_626075093d7d40e986d72eff4957ae35"
          }
        },
        "bd9f4a4ba9ae45dfb880f3a0bdd57551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dee018f1eaca498ebcaddea80d182a0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91e7db48c0f046a0bfc72e695f99223e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "626075093d7d40e986d72eff4957ae35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlQ9thHZSDVz"
      },
      "source": [
        " # cnn model trained on CIFAR-10 dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1XFrQqz7TPg"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torch.utils.data import Dataset,DataLoader\r\n",
        "\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApoqEveKEvl0"
      },
      "source": [
        "# transformations\r\n",
        "composed = transforms.Compose([\r\n",
        "                         transforms.ToTensor(),\r\n",
        "                         transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\r\n",
        "                        ])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "b0f1ce5483b346b5b337cbc41543a2a4",
            "b3dbf7ce28d84be491b4347e46d35bc7",
            "07d2ec5b2bf1434f84473648c3765bc4",
            "1aee3aa0d8e9437c9226f22ee4a409cb",
            "bd9f4a4ba9ae45dfb880f3a0bdd57551",
            "dee018f1eaca498ebcaddea80d182a0c",
            "91e7db48c0f046a0bfc72e695f99223e",
            "626075093d7d40e986d72eff4957ae35"
          ]
        },
        "id": "fXqEUVz_EiSH",
        "outputId": "a82dad0c-cd83-4bbf-dcb9-f3a1046b924a"
      },
      "source": [
        "# CIFAR-10 dataset\r\n",
        "train_data = torchvision.datasets.CIFAR10(root='./data',train=True,\r\n",
        "                                          download=True,transform=composed)\r\n",
        "\r\n",
        "test_data = torchvision.datasets.CIFAR10(root='./data',train=False,\r\n",
        "                                         download=True,transform=composed)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0f1ce5483b346b5b337cbc41543a2a4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIDs8ZN9G2YQ",
        "outputId": "27cfb3c9-87f7-4268-a55a-330a75a87175"
      },
      "source": [
        "# hyperparameters\r\n",
        "batch_size = 4\r\n",
        "num_epochs = 10\r\n",
        "learning_rate = 0.01\r\n",
        "\r\n",
        "# device\r\n",
        "device = None\r\n",
        "if torch.cuda.is_available():\r\n",
        "    device = torch.device('cuda')\r\n",
        "else:\r\n",
        "    device = torch.device('cpu')\r\n",
        "\r\n",
        "print(device)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3xij_JyGoKy"
      },
      "source": [
        "# DataLoaders\r\n",
        "\r\n",
        "train_loader = DataLoader(dataset=train_data,\r\n",
        "                          batch_size=batch_size,\r\n",
        "                          shuffle=True,\r\n",
        "                          num_workers=2)\r\n",
        "\r\n",
        "test_loader = DataLoader(dataset=test_data,\r\n",
        "                         batch_size=batch_size,\r\n",
        "                         shuffle=False,\r\n",
        "                         num_workers=2)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXgJ7A4QHhvE",
        "outputId": "efbd1837-44e1-4a0c-ef52-2350ef04a468"
      },
      "source": [
        "len(train_loader),len(test_loader)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12500, 2500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJSdNYJOHmGx",
        "outputId": "449e0bd0-6922-49a4-952e-00b9c242b27d"
      },
      "source": [
        "# label classes\r\n",
        "classes = ('plane', 'car', 'bird', 'cat',\r\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\r\n",
        "\r\n",
        "num_classes = len(classes)\r\n",
        "print(num_classes)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97yF_F-YH1US"
      },
      "source": [
        "# model class\r\n",
        "class ConvNet(nn.Module):\r\n",
        "    def __init__(self,num_classes):\r\n",
        "        super(ConvNet,self).__init__()\r\n",
        "        \r\n",
        "        # cnn layers\r\n",
        "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=6,kernel_size=5)\r\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\r\n",
        "        self.conv2 = nn.Conv2d(in_channels=6,out_channels=16,kernel_size=5)\r\n",
        "        \r\n",
        "        #fc layers\r\n",
        "        self.linear1 = nn.Linear(in_features=16*5*5,out_features=120)\r\n",
        "        self.linear2 = nn.Linear(in_features=120,out_features=84)\r\n",
        "        self.linear3 = nn.Linear(in_features=84,out_features=num_classes)\r\n",
        "\r\n",
        "    def forward(self,x):\r\n",
        "        x1 = self.pool(F.relu(self.conv1(x)))\r\n",
        "        x2 = self.pool(F.relu(self.conv2(x1)))\r\n",
        "        x2_flat = x2.view(-1,16*5*5) # Flatten\r\n",
        "        x3 = F.relu(self.linear1(x2_flat))\r\n",
        "        x4 = F.relu(self.linear2(x3))\r\n",
        "        x5 = F.relu(self.linear3(x4))\r\n",
        "        return x5"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4NrpyJAH590"
      },
      "source": [
        "# model defining\r\n",
        "model = ConvNet(num_classes)\r\n",
        "model = model.to(device)\r\n",
        "\r\n",
        "# loss and optimizer\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3hwFeVmH58W",
        "outputId": "171dd79e-52b1-4ad3-b916-b00c48e0f6f8"
      },
      "source": [
        "n_total_steps = len(train_loader)\r\n",
        "\r\n",
        "# training loop\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    for ii,(images,labels) in enumerate(train_loader):\r\n",
        "        # original shape = [4,3,32,32] : 4 := batch_size, 3 := RGB, dims =32x32\r\n",
        "        # input_layer = 3 input_channels, 6 output_channels, 5 kernel_size\r\n",
        "        images = images.to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "\r\n",
        "        # forward\r\n",
        "        outputs = model(images)\r\n",
        "        loss = criterion(outputs,labels)\r\n",
        "\r\n",
        "        # backward and updates\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        if (ii+1)%2000 == 0:\r\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{ii+1}/{n_total_steps}], Loss = {loss.item():.6f}')\r\n",
        "\r\n",
        "    print('----------------------------------------')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [2000/12500], Loss = 2.596829\n",
            "Epoch [1/10], Step [4000/12500], Loss = 1.889913\n",
            "Epoch [1/10], Step [6000/12500], Loss = 2.193358\n",
            "Epoch [1/10], Step [8000/12500], Loss = 2.971833\n",
            "Epoch [1/10], Step [10000/12500], Loss = 3.085864\n",
            "Epoch [1/10], Step [12000/12500], Loss = 1.033718\n",
            "----------------------------------------\n",
            "Epoch [2/10], Step [2000/12500], Loss = 1.552075\n",
            "Epoch [2/10], Step [4000/12500], Loss = 1.272144\n",
            "Epoch [2/10], Step [6000/12500], Loss = 1.682622\n",
            "Epoch [2/10], Step [8000/12500], Loss = 0.977196\n",
            "Epoch [2/10], Step [10000/12500], Loss = 0.737638\n",
            "Epoch [2/10], Step [12000/12500], Loss = 1.521685\n",
            "----------------------------------------\n",
            "Epoch [3/10], Step [2000/12500], Loss = 2.104290\n",
            "Epoch [3/10], Step [4000/12500], Loss = 1.776286\n",
            "Epoch [3/10], Step [6000/12500], Loss = 0.531293\n",
            "Epoch [3/10], Step [8000/12500], Loss = 0.830762\n",
            "Epoch [3/10], Step [10000/12500], Loss = 1.024097\n",
            "Epoch [3/10], Step [12000/12500], Loss = 0.833280\n",
            "----------------------------------------\n",
            "Epoch [4/10], Step [2000/12500], Loss = 1.254686\n",
            "Epoch [4/10], Step [4000/12500], Loss = 2.320066\n",
            "Epoch [4/10], Step [6000/12500], Loss = 1.488582\n",
            "Epoch [4/10], Step [8000/12500], Loss = 1.347188\n",
            "Epoch [4/10], Step [10000/12500], Loss = 2.073813\n",
            "Epoch [4/10], Step [12000/12500], Loss = 0.308610\n",
            "----------------------------------------\n",
            "Epoch [5/10], Step [2000/12500], Loss = 0.398242\n",
            "Epoch [5/10], Step [4000/12500], Loss = 1.288155\n",
            "Epoch [5/10], Step [6000/12500], Loss = 0.594539\n",
            "Epoch [5/10], Step [8000/12500], Loss = 0.561702\n",
            "Epoch [5/10], Step [10000/12500], Loss = 1.598136\n",
            "Epoch [5/10], Step [12000/12500], Loss = 0.132812\n",
            "----------------------------------------\n",
            "Epoch [6/10], Step [2000/12500], Loss = 0.424000\n",
            "Epoch [6/10], Step [4000/12500], Loss = 0.989117\n",
            "Epoch [6/10], Step [6000/12500], Loss = 1.569141\n",
            "Epoch [6/10], Step [8000/12500], Loss = 1.377899\n",
            "Epoch [6/10], Step [10000/12500], Loss = 1.390290\n",
            "Epoch [6/10], Step [12000/12500], Loss = 1.141804\n",
            "----------------------------------------\n",
            "Epoch [7/10], Step [2000/12500], Loss = 1.806845\n",
            "Epoch [7/10], Step [4000/12500], Loss = 0.796387\n",
            "Epoch [7/10], Step [6000/12500], Loss = 1.641474\n",
            "Epoch [7/10], Step [8000/12500], Loss = 0.635098\n",
            "Epoch [7/10], Step [10000/12500], Loss = 0.480813\n",
            "Epoch [7/10], Step [12000/12500], Loss = 2.124436\n",
            "----------------------------------------\n",
            "Epoch [8/10], Step [2000/12500], Loss = 0.788681\n",
            "Epoch [8/10], Step [4000/12500], Loss = 1.874619\n",
            "Epoch [8/10], Step [6000/12500], Loss = 1.986616\n",
            "Epoch [8/10], Step [8000/12500], Loss = 0.863881\n",
            "Epoch [8/10], Step [10000/12500], Loss = 0.495287\n",
            "Epoch [8/10], Step [12000/12500], Loss = 1.757683\n",
            "----------------------------------------\n",
            "Epoch [9/10], Step [2000/12500], Loss = 0.450091\n",
            "Epoch [9/10], Step [4000/12500], Loss = 0.766397\n",
            "Epoch [9/10], Step [6000/12500], Loss = 1.214233\n",
            "Epoch [9/10], Step [8000/12500], Loss = 0.468651\n",
            "Epoch [9/10], Step [10000/12500], Loss = 1.155880\n",
            "Epoch [9/10], Step [12000/12500], Loss = 1.633752\n",
            "----------------------------------------\n",
            "Epoch [10/10], Step [2000/12500], Loss = 0.960961\n",
            "Epoch [10/10], Step [4000/12500], Loss = 0.583701\n",
            "Epoch [10/10], Step [6000/12500], Loss = 0.560628\n",
            "Epoch [10/10], Step [8000/12500], Loss = 0.507220\n",
            "Epoch [10/10], Step [10000/12500], Loss = 2.150919\n",
            "Epoch [10/10], Step [12000/12500], Loss = 0.251208\n",
            "----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3sX3FB1NVhp",
        "outputId": "dedee0fa-bf24-4b41-b76e-8e0c621d2596"
      },
      "source": [
        "# evaluating model\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "    # for entire test set\r\n",
        "    n_correct = 0\r\n",
        "    n_samples = 0\r\n",
        "\r\n",
        "    # for each class label\r\n",
        "    n_class_correct = [0 for i in range(num_classes)]\r\n",
        "    n_class_samples = [0 for i in range(num_classes)]\r\n",
        "\r\n",
        "    for images,labels in test_loader:\r\n",
        "        images = images.to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "\r\n",
        "        outputs = model(images)\r\n",
        "\r\n",
        "        _,preds = torch.max(outputs,1)\r\n",
        "        n_samples += labels.size(0)\r\n",
        "        n_correct += (preds == labels).sum().item()\r\n",
        "\r\n",
        "        # iterating over the batch \r\n",
        "        for i in range(batch_size):\r\n",
        "            label = labels[i]\r\n",
        "            pred = preds[i]\r\n",
        "            n_class_samples[label] +=1\r\n",
        "            if(label == pred):\r\n",
        "                n_class_correct[label] += 1\r\n",
        "            \r\n",
        "    accuracy = n_correct/float(n_samples)\r\n",
        "    print(f'Accuracy of model on test set = {accuracy:.4f}')\r\n",
        "    \r\n",
        "    print('-------------------------------------------')\r\n",
        "    \r\n",
        "    # printing accuracy per class\r\n",
        "    for i in range(num_classes):\r\n",
        "        accuracy = n_class_correct[i]/float(n_class_samples[i])\r\n",
        "        print(f'Accuracy of {classes[i]} : {accuracy}')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model on test set = 0.6430\n",
            "-------------------------------------------\n",
            "Accuracy of plane : 0.711\n",
            "Accuracy of car : 0.846\n",
            "Accuracy of bird : 0.43\n",
            "Accuracy of cat : 0.524\n",
            "Accuracy of deer : 0.644\n",
            "Accuracy of dog : 0.473\n",
            "Accuracy of frog : 0.7\n",
            "Accuracy of horse : 0.72\n",
            "Accuracy of ship : 0.738\n",
            "Accuracy of truck : 0.644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUvQMrM3TaQP"
      },
      "source": [
        "# saving model\r\n",
        "MODEL_PATH = 'model.pth'\r\n",
        "torch.save(model.state_dict(),MODEL_PATH)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0rXrnerQdoN",
        "outputId": "be7216bc-4302-4b82-f9d2-42a82bcc4b10"
      },
      "source": [
        "# printing parameters of the model\r\n",
        "\r\n",
        "for param in model.parameters():\r\n",
        "    print(param.shape)\r\n",
        "    print(str(param))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6, 3, 5, 5])\n",
            "Parameter containing:\n",
            "tensor([[[[ 3.3287e-01,  6.0073e-01,  6.1119e-01,  5.1291e-01,  2.4391e-01],\n",
            "          [ 2.1776e-01,  1.6950e-01,  3.6638e-01,  3.6824e-02,  1.2162e-01],\n",
            "          [-6.8717e-02, -2.3781e-01, -2.7297e-02, -1.3946e-01,  3.2651e-01],\n",
            "          [ 1.1522e-01, -2.6747e-01, -3.9195e-01, -1.4185e-01,  6.0015e-01],\n",
            "          [-3.9254e-01, -6.6540e-01, -5.8051e-01, -2.2269e-01,  2.9562e-01]],\n",
            "\n",
            "         [[-6.4331e-01, -4.6063e-01, -5.9473e-01, -5.8637e-01, -5.5769e-01],\n",
            "          [-3.1318e-01, -3.1919e-01, -3.7058e-01, -3.4217e-01, -1.4683e-01],\n",
            "          [-6.9673e-02, -4.7429e-01, -5.1814e-01, -1.1666e-01,  3.0737e-01],\n",
            "          [ 1.6787e-01, -5.8573e-01, -5.1279e-01, -4.0897e-02,  5.0933e-01],\n",
            "          [ 6.7994e-02, -3.9576e-01, -1.4911e-01,  1.3233e-01,  5.5746e-01]],\n",
            "\n",
            "         [[-8.1871e-02,  1.9333e-01,  2.1725e-01,  1.1576e-01, -3.5592e-01],\n",
            "          [ 2.1050e-01,  3.4375e-02,  1.5371e-01,  1.9345e-01, -1.1610e-01],\n",
            "          [ 7.8045e-02, -1.0473e-01,  5.7621e-02,  8.1838e-02,  2.9242e-01],\n",
            "          [ 1.9939e-01, -4.1723e-01, -2.9779e-01,  1.3554e-02,  4.7033e-01],\n",
            "          [-8.7363e-02, -2.5204e-01, -8.3388e-02,  2.9400e-01,  4.1586e-01]]],\n",
            "\n",
            "\n",
            "        [[[-8.6099e-02, -7.3495e-02,  1.4763e-01,  2.1713e-01,  2.8549e-01],\n",
            "          [ 1.5743e-02,  2.5322e-01,  1.5517e-01, -1.7979e-02, -5.9760e-02],\n",
            "          [-1.3648e-03,  3.3276e-01,  2.7975e-01,  8.1666e-02, -3.2497e-01],\n",
            "          [ 9.9739e-02,  2.8480e-01,  1.4092e-01, -1.4389e-01, -6.6315e-02],\n",
            "          [ 4.2222e-02,  9.1530e-02,  5.3355e-02,  1.4839e-02,  5.7876e-02]],\n",
            "\n",
            "         [[-1.0640e-01, -1.2564e-01, -8.8781e-02, -1.3526e-01,  8.5203e-02],\n",
            "          [-1.6091e-01,  2.1680e-01,  1.7333e-01, -3.4046e-01, -2.9919e-01],\n",
            "          [ 6.4868e-02,  3.2959e-01,  1.2757e-01, -2.7194e-01, -6.4951e-01],\n",
            "          [ 5.5019e-02,  2.0754e-01, -1.1400e-01, -3.8892e-01, -5.1207e-01],\n",
            "          [-2.1013e-02,  1.3445e-02, -2.2592e-01, -1.4666e-01, -1.8422e-01]],\n",
            "\n",
            "         [[ 9.4889e-02, -2.0729e-02,  1.0293e-01,  4.3407e-02, -1.3621e-01],\n",
            "          [ 1.9520e-01,  5.8360e-01,  3.9674e-01, -3.4897e-01, -5.9266e-01],\n",
            "          [ 2.8323e-01,  7.1607e-01,  2.5187e-01, -3.7544e-01, -7.4322e-01],\n",
            "          [ 3.0083e-01,  6.6835e-01,  1.7699e-01, -3.0021e-01, -5.4933e-01],\n",
            "          [ 9.2591e-02,  4.3050e-01,  1.9950e-01, -8.0235e-02,  6.8774e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.2728e-01, -2.2269e-01,  1.5197e-01,  1.5061e-01, -3.1524e-01],\n",
            "          [ 1.2984e-01, -6.3188e-01, -5.9711e-01, -2.5105e-01,  2.5332e-01],\n",
            "          [ 1.7281e-01, -4.3392e-01, -1.0716e+00, -5.8735e-01,  2.0096e-02],\n",
            "          [ 5.9949e-02,  7.7913e-01,  7.9031e-01,  1.9965e-02, -1.7827e-01],\n",
            "          [ 1.6247e-01,  4.2635e-01,  6.0317e-01,  5.4591e-01,  1.8286e-01]],\n",
            "\n",
            "         [[-1.4844e-01,  9.4553e-02,  4.8164e-01,  3.8598e-01,  5.6391e-02],\n",
            "          [ 2.6866e-01, -2.9363e-01, -3.1025e-01, -5.8863e-02,  5.0617e-01],\n",
            "          [ 3.0954e-01, -3.0259e-01, -7.5871e-01, -3.3720e-01,  1.7286e-01],\n",
            "          [-1.7874e-01,  5.8531e-01,  5.3177e-01,  8.0285e-03, -3.4137e-01],\n",
            "          [-4.6840e-01,  1.0035e-01,  3.5724e-01,  1.5431e-01, -4.8434e-01]],\n",
            "\n",
            "         [[-1.5607e-01, -7.9746e-02,  1.9928e-01,  1.0283e-01, -1.3261e-01],\n",
            "          [ 1.8858e-01, -6.1867e-01, -4.2430e-01, -1.8014e-01,  5.1987e-01],\n",
            "          [ 2.9307e-01, -4.0605e-01, -7.8833e-01, -2.3012e-01,  3.0866e-01],\n",
            "          [-5.9349e-02,  6.8912e-01,  5.5066e-01,  3.4165e-02, -1.7118e-01],\n",
            "          [-8.5508e-02,  1.6071e-01,  2.9159e-01,  3.0839e-01, -2.2833e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2896e-01, -9.1529e-02, -3.2269e-01,  1.4500e-01,  1.9849e-01],\n",
            "          [ 5.2670e-01,  7.7620e-01,  1.0371e+00,  1.1050e+00,  3.8323e-01],\n",
            "          [-1.0143e-02,  5.0472e-01,  7.4085e-01,  4.0119e-01, -8.0394e-02],\n",
            "          [-3.6586e-01, -5.1530e-01, -8.6555e-01, -9.0672e-01, -5.2978e-01],\n",
            "          [-3.7035e-01, -3.8026e-01, -3.9284e-01, -2.1562e-01, -4.4057e-01]],\n",
            "\n",
            "         [[-1.0249e-01, -5.6912e-01, -4.9025e-01, -3.8846e-01, -2.3396e-01],\n",
            "          [ 2.7959e-01,  4.3572e-01,  5.5666e-01,  6.1786e-01, -2.9307e-02],\n",
            "          [-2.4017e-01,  2.3330e-01,  3.2917e-01, -1.1064e-01, -4.3935e-01],\n",
            "          [-1.4826e-01, -5.6947e-01, -9.2491e-01, -7.7441e-01, -3.2840e-01],\n",
            "          [ 4.3406e-02,  1.8841e-01,  2.7671e-01,  2.6393e-01,  2.5311e-01]],\n",
            "\n",
            "         [[-2.1029e-01, -5.2404e-01, -6.0243e-01, -2.5613e-01,  5.4625e-02],\n",
            "          [ 2.3401e-01,  3.2930e-01,  2.8840e-01,  5.1608e-01,  1.8304e-02],\n",
            "          [ 8.5299e-03,  2.8250e-01,  2.0820e-01,  3.6195e-02, -1.3826e-01],\n",
            "          [ 3.9493e-02, -2.6582e-01, -5.8742e-01, -5.9862e-01, -4.5273e-02],\n",
            "          [ 1.9995e-01,  2.5273e-01,  3.9040e-01,  5.2184e-01,  3.7569e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0649e-01, -8.9554e-02, -2.2295e-01, -2.2484e-02,  2.5557e-01],\n",
            "          [-1.5980e-01, -1.4590e-01, -3.0306e-01, -3.0678e-01, -8.6021e-02],\n",
            "          [-3.7372e-01, -4.4605e-01, -3.0383e-01, -2.8095e-01, -1.9094e-01],\n",
            "          [-2.5513e-01, -2.2624e-01, -4.4793e-01, -3.5957e-01, -5.5061e-02],\n",
            "          [-1.7561e-01, -2.1851e-01, -4.3234e-01, -9.8890e-02, -1.3883e-01]],\n",
            "\n",
            "         [[-5.3829e-02,  2.4536e-02, -1.5180e-01, -4.4498e-02,  2.1119e-01],\n",
            "          [-5.7655e-03,  1.9033e-01,  2.3017e-01, -1.2246e-01,  2.6406e-01],\n",
            "          [-1.2614e-01, -2.7060e-02,  1.2797e-01, -5.2747e-03,  3.8164e-02],\n",
            "          [-2.5106e-01,  7.3985e-02, -1.6175e-02,  2.9600e-01,  7.8610e-02],\n",
            "          [-2.1857e-01,  1.5733e-01,  1.4246e-02,  6.2443e-02, -1.1257e-01]],\n",
            "\n",
            "         [[ 2.9050e-02,  1.6958e-01,  9.0013e-02,  5.6491e-03, -1.1045e-01],\n",
            "          [ 2.3031e-01,  5.0865e-01,  3.3673e-01,  1.8547e-01,  3.7657e-02],\n",
            "          [-2.7464e-02,  3.7853e-01,  3.6350e-01,  2.4493e-01, -1.2552e-01],\n",
            "          [ 7.4563e-02,  5.6650e-01,  3.1961e-01,  5.0818e-01, -1.1184e-02],\n",
            "          [ 5.9983e-02,  4.3629e-01,  3.7031e-01,  3.4923e-01, -2.0167e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.4932e-01,  2.0846e-01,  8.1571e-03,  5.3611e-02, -2.0148e-02],\n",
            "          [-2.6074e-01,  3.2191e-01,  6.1331e-02,  1.2395e-01, -2.1092e-01],\n",
            "          [-4.2978e-01,  5.4667e-01, -1.3223e-01, -1.3341e-02, -3.3426e-01],\n",
            "          [ 8.3083e-01,  1.8207e-01, -1.5892e+00,  1.1719e+00, -2.0551e-01],\n",
            "          [ 8.4590e-01, -5.7271e-01, -2.0187e+00,  1.4461e+00, -2.3856e-01]],\n",
            "\n",
            "         [[ 1.0607e-01,  9.2637e-02, -2.3366e-01,  8.6682e-02, -1.1475e-01],\n",
            "          [ 6.8907e-02,  4.7806e-02, -1.4881e-01,  3.2153e-01,  2.7735e-02],\n",
            "          [-1.7623e-01,  2.8737e-01, -3.1404e-01,  3.7121e-01, -1.2902e-01],\n",
            "          [ 1.0785e+00,  1.7568e-02, -1.7131e+00,  1.2518e+00, -1.3548e-01],\n",
            "          [ 8.1545e-01, -6.3907e-01, -1.8763e+00,  1.5711e+00, -1.5457e-01]],\n",
            "\n",
            "         [[-7.2086e-02, -1.8737e-03, -1.1979e-01,  3.9657e-02, -2.3301e-01],\n",
            "          [-9.3080e-02,  1.4041e-01, -1.5509e-01,  1.7472e-01, -2.1102e-01],\n",
            "          [-5.4555e-01,  2.2160e-01, -1.7973e-02,  3.2280e-01, -3.9384e-01],\n",
            "          [ 4.9065e-01,  6.6246e-02, -1.2003e+00,  1.2960e+00, -3.9969e-01],\n",
            "          [ 5.8261e-01, -3.3430e-01, -1.3898e+00,  1.6703e+00, -1.4605e-01]]]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "torch.Size([6])\n",
            "Parameter containing:\n",
            "tensor([-0.7706, -0.1983, -0.5043, -0.8483,  0.5639, -0.3101], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "torch.Size([16, 6, 5, 5])\n",
            "Parameter containing:\n",
            "tensor([[[[ 0.4130,  0.0399, -0.1983,  0.0243,  0.1100],\n",
            "          [ 0.2449,  0.2043, -0.1318, -0.1682, -0.0846],\n",
            "          [ 0.1466,  0.3618,  0.0894, -0.1083,  0.0089],\n",
            "          [-0.0032,  0.1511,  0.0901,  0.0682, -0.0720],\n",
            "          [ 0.0372,  0.1819, -0.0400,  0.0987,  0.0259]],\n",
            "\n",
            "         [[-0.1310,  0.3207,  0.1656, -0.2110,  0.2649],\n",
            "          [-0.3884, -0.1725,  0.3282,  0.1071,  0.1108],\n",
            "          [-0.2157, -0.3653, -0.0252,  0.3475,  0.3931],\n",
            "          [-0.2456, -0.1319, -0.1474, -0.0725,  0.2384],\n",
            "          [-0.0859, -0.1040,  0.0132, -0.0356, -0.2194]],\n",
            "\n",
            "         [[-0.4566, -0.0693,  0.5173,  0.4430, -0.0852],\n",
            "          [-0.5931, -0.5678, -0.0735,  0.5798,  0.0789],\n",
            "          [-0.1552, -0.2975, -0.3098,  0.1018,  0.4950],\n",
            "          [-0.0198, -0.0489, -0.0028, -0.0833,  0.2013],\n",
            "          [ 0.1013,  0.0729,  0.0819,  0.0922,  0.0887]],\n",
            "\n",
            "         [[-0.2889, -0.1274, -0.0501, -0.0570, -0.1487],\n",
            "          [-0.3533, -0.3427, -0.3899, -0.2110, -0.2450],\n",
            "          [-0.2757, -0.2719, -0.2802, -0.3206, -0.1523],\n",
            "          [-0.2522, -0.2406, -0.2990, -0.0069, -0.0246],\n",
            "          [-0.0987, -0.2476, -0.2476, -0.1779,  0.0533]],\n",
            "\n",
            "         [[ 0.0876, -0.1838, -0.2081, -0.1870, -0.0399],\n",
            "          [ 0.3107,  0.1111, -0.0272, -0.1650, -0.1944],\n",
            "          [ 0.0662,  0.1359,  0.1228, -0.1049, -0.2121],\n",
            "          [ 0.0608,  0.0458,  0.1083,  0.1165, -0.0771],\n",
            "          [ 0.2066,  0.0384,  0.1938,  0.2031,  0.0794]],\n",
            "\n",
            "         [[-0.2365, -0.0347, -0.0581,  0.3526,  0.0698],\n",
            "          [-0.1522,  0.0180, -0.2195, -0.1055,  0.1939],\n",
            "          [-0.1040,  0.0048, -0.1171, -0.1339, -0.1083],\n",
            "          [-0.2335, -0.1124, -0.2086, -0.1121, -0.1145],\n",
            "          [-0.3131, -0.1102, -0.2375, -0.3129,  0.0212]]],\n",
            "\n",
            "\n",
            "        [[[-0.2156,  0.0783,  0.0425, -0.2481, -0.1700],\n",
            "          [-0.1273,  0.0611, -0.0903, -0.2179, -0.1495],\n",
            "          [-0.0488,  0.1842, -0.0011, -0.0548,  0.0200],\n",
            "          [-0.1306,  0.1278,  0.1176,  0.2064,  0.3914],\n",
            "          [-0.4827, -0.2175, -0.1086, -0.1408, -0.0031]],\n",
            "\n",
            "         [[-0.0973, -0.1039,  0.0781, -0.4121, -0.2128],\n",
            "          [-0.0202, -0.0930,  0.1315, -0.1969, -0.0972],\n",
            "          [-0.0676, -0.1046,  0.1319, -0.2816, -0.3625],\n",
            "          [ 0.0801,  0.1049,  0.3434, -0.0960, -0.2485],\n",
            "          [-0.0083,  0.1235,  0.1529, -0.1344, -0.2908]],\n",
            "\n",
            "         [[-0.0661, -0.0532, -0.1987, -0.2044, -0.1826],\n",
            "          [-0.1499, -0.2906, -0.3158, -0.3000, -0.2841],\n",
            "          [ 0.0382, -0.1727, -0.2055,  0.1243,  0.0657],\n",
            "          [-0.1734, -0.2407, -0.2730, -0.1859, -0.1264],\n",
            "          [-0.1134, -0.1440, -0.2938, -0.2617,  0.0212]],\n",
            "\n",
            "         [[-0.2940, -0.3007, -0.2773, -0.2130, -0.1960],\n",
            "          [-0.0906, -0.0905, -0.1434, -0.0836,  0.0119],\n",
            "          [ 0.2271,  0.2913,  0.5220,  0.6397,  0.5948],\n",
            "          [ 0.3067,  0.1594,  0.1685,  0.1952,  0.1464],\n",
            "          [ 0.1194,  0.0583, -0.1612, -0.2578, -0.1787]],\n",
            "\n",
            "         [[-0.0047, -0.1600, -0.0271,  0.0368, -0.0465],\n",
            "          [-0.0519, -0.0252, -0.1285, -0.0078,  0.0563],\n",
            "          [ 0.0216,  0.0203,  0.1336,  0.0890,  0.0291],\n",
            "          [ 0.0568,  0.0731,  0.1892, -0.0805, -0.0541],\n",
            "          [-0.0875, -0.0263, -0.1029, -0.1901, -0.1940]],\n",
            "\n",
            "         [[-0.2217,  0.1490,  0.0935, -0.1102, -0.2522],\n",
            "          [-0.3641, -0.2106, -0.1222, -0.3486, -0.1493],\n",
            "          [-0.1840, -0.0911, -0.0248, -0.0907, -0.0600],\n",
            "          [ 0.0801,  0.4218,  0.4180,  0.2723,  0.0577],\n",
            "          [-0.0173,  0.1995,  0.2485,  0.2319, -0.1301]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3705,  0.0596, -0.0281,  0.1705, -0.1560],\n",
            "          [ 0.1752,  0.2275, -0.3393,  0.3326, -0.1762],\n",
            "          [ 0.2124,  0.1865, -0.3802,  0.4303,  0.1470],\n",
            "          [ 0.0125,  0.2039, -0.3531,  0.0350, -0.0805],\n",
            "          [-0.0481,  0.0630, -0.1137, -0.1479, -0.3378]],\n",
            "\n",
            "         [[ 0.0327,  0.3017,  0.3897, -0.0713,  0.4122],\n",
            "          [-0.0210, -0.0759,  0.5945, -0.4568,  0.1708],\n",
            "          [ 0.0097, -0.4345,  0.6385, -0.4010,  0.1814],\n",
            "          [-0.0126, -0.4160,  0.5521,  0.0907,  0.1903],\n",
            "          [ 0.1189, -0.2845,  0.1572, -0.0632, -0.0696]],\n",
            "\n",
            "         [[ 0.0126, -0.2287, -0.1393, -0.3414, -0.1846],\n",
            "          [-0.0533, -0.3673, -0.3752, -0.4091, -0.2282],\n",
            "          [ 0.1556, -0.1429, -0.4202, -0.1955, -0.3340],\n",
            "          [ 0.2673, -0.0068, -0.2726,  0.1061,  0.0819],\n",
            "          [ 0.0401, -0.0364, -0.2907, -0.1645, -0.1940]],\n",
            "\n",
            "         [[ 0.2138, -0.1914, -0.0673, -0.0539,  0.1559],\n",
            "          [-0.0670, -0.3639, -0.2344, -0.0946,  0.0519],\n",
            "          [ 0.0692, -0.3433, -0.3393, -0.1213,  0.1493],\n",
            "          [ 0.1207,  0.0114, -0.2568, -0.2601, -0.0127],\n",
            "          [ 0.2557,  0.1094,  0.0319, -0.2722,  0.0557]],\n",
            "\n",
            "         [[ 0.1433, -0.1671, -0.2594, -0.0798,  0.0802],\n",
            "          [ 0.0891, -0.1418, -0.0571, -0.1666,  0.0617],\n",
            "          [ 0.0858, -0.0785, -0.1258, -0.2127,  0.0402],\n",
            "          [-0.0021, -0.0727, -0.1112, -0.1540, -0.0240],\n",
            "          [ 0.1978,  0.0355, -0.0181, -0.1493, -0.0694]],\n",
            "\n",
            "         [[ 0.0844,  0.2062, -0.0511,  0.2633, -0.0358],\n",
            "          [-0.1211,  0.1952, -0.0320,  0.2285, -0.2485],\n",
            "          [-0.1369, -0.1348, -0.0549,  0.3161, -0.0508],\n",
            "          [ 0.0309, -0.1269,  0.1127,  0.1188,  0.0185],\n",
            "          [ 0.0585, -0.2556, -0.1090, -0.1443,  0.0305]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0652, -0.5605, -0.2473,  0.0502, -0.0084],\n",
            "          [ 0.3755,  0.3621, -0.4002, -0.1929, -0.1363],\n",
            "          [-0.2628,  0.5278,  0.1317, -0.1575, -0.3681],\n",
            "          [-0.0830, -0.1836,  0.4499,  0.2152,  0.0029],\n",
            "          [ 0.0668, -0.2049,  0.0037,  0.2645,  0.1461]],\n",
            "\n",
            "         [[-0.0365,  0.1333,  0.0057,  0.0604,  0.0054],\n",
            "          [-0.3829, -0.2864,  0.0144,  0.2871, -0.0188],\n",
            "          [ 0.1807, -0.5013, -0.5928,  0.0763,  0.0116],\n",
            "          [ 0.1778,  0.3522, -0.5294, -0.5229, -0.1960],\n",
            "          [-0.0370, -0.0451,  0.2019, -0.0302, -0.0464]],\n",
            "\n",
            "         [[-0.0316,  0.2930,  0.1357, -0.0145, -0.0425],\n",
            "          [-0.2412, -0.1751,  0.2088,  0.1260,  0.1563],\n",
            "          [ 0.5766, -0.0349, -0.4166, -0.1161, -0.1992],\n",
            "          [-0.5402,  0.7355,  0.2402, -0.1862, -0.4592],\n",
            "          [-0.0500, -0.2222,  0.2849,  0.1938, -0.0451]],\n",
            "\n",
            "         [[ 0.1825,  0.0704, -0.1330, -0.0992,  0.0657],\n",
            "          [ 0.0760,  0.2162, -0.2209, -0.1159,  0.1000],\n",
            "          [-0.1312,  0.1466,  0.0723, -0.1029, -0.4134],\n",
            "          [-0.3619, -0.3427,  0.1011,  0.4181, -0.2191],\n",
            "          [-0.2651, -0.1132, -0.1580, -0.0558,  0.4428]],\n",
            "\n",
            "         [[ 0.0056,  0.2620, -0.0147, -0.0645, -0.0564],\n",
            "          [-0.1879,  0.0084,  0.1715,  0.1604,  0.1613],\n",
            "          [-0.1766, -0.2552,  0.1327,  0.0925,  0.0976],\n",
            "          [-0.2161, -0.1340, -0.0492,  0.1235, -0.0678],\n",
            "          [ 0.0687, -0.0177, -0.1192,  0.0161, -0.2855]],\n",
            "\n",
            "         [[ 0.1392, -0.3618, -0.2386, -0.0860, -0.1704],\n",
            "          [ 0.0566,  0.3053, -0.4928, -0.0651,  0.0144],\n",
            "          [-0.1474,  0.1080,  0.5231, -0.2052, -0.1003],\n",
            "          [ 0.1836, -0.2053,  0.2867,  0.1729,  0.0983],\n",
            "          [-0.0478,  0.0664, -0.1274, -0.1157, -0.2396]]],\n",
            "\n",
            "\n",
            "        [[[-0.2480, -0.3324, -0.3855, -0.3552,  0.0332],\n",
            "          [-0.0962, -0.2349, -0.1417, -0.0696,  0.1248],\n",
            "          [ 0.2162,  0.2439,  0.2174,  0.1231,  0.2611],\n",
            "          [ 0.1594,  0.1104,  0.1907,  0.2116,  0.1912],\n",
            "          [-0.0653, -0.1335, -0.1663, -0.1917, -0.1240]],\n",
            "\n",
            "         [[-0.0255, -0.1319, -0.3410, -0.0529, -0.2701],\n",
            "          [ 0.1587, -0.0392, -0.3938, -0.3812, -0.0904],\n",
            "          [ 0.1469, -0.0207, -0.1683, -0.2570, -0.1213],\n",
            "          [ 0.1841, -0.1382, -0.0204, -0.1552, -0.0816],\n",
            "          [-0.0308, -0.0408, -0.0155, -0.0736,  0.0504]],\n",
            "\n",
            "         [[ 0.1183,  0.0988,  0.1844, -0.0307,  0.1187],\n",
            "          [ 0.2298,  0.0955, -0.1171,  0.0785,  0.1678],\n",
            "          [ 0.1849,  0.3353,  0.1842,  0.1701,  0.1405],\n",
            "          [ 0.2076,  0.0775, -0.0199,  0.0777,  0.2503],\n",
            "          [-0.1174, -0.0635, -0.0699,  0.0986,  0.0018]],\n",
            "\n",
            "         [[ 0.4213,  0.0018,  0.1182,  0.2017,  0.1240],\n",
            "          [ 0.2672, -0.0308, -0.0615, -0.1473,  0.6043],\n",
            "          [ 0.1353,  0.0866,  0.1372, -0.0401,  0.2726],\n",
            "          [ 0.2996,  0.2634,  0.2734,  0.1149,  0.1028],\n",
            "          [-0.0131,  0.1184,  0.2015,  0.1123,  0.0983]],\n",
            "\n",
            "         [[ 0.0985,  0.0049,  0.1617,  0.1716,  0.2906],\n",
            "          [ 0.1665, -0.0442,  0.0109,  0.1805,  0.2212],\n",
            "          [ 0.1307, -0.1480, -0.2276, -0.1151, -0.0508],\n",
            "          [ 0.2685, -0.0193, -0.0305, -0.1962, -0.3300],\n",
            "          [ 0.3522,  0.0896,  0.0439,  0.0116, -0.1534]],\n",
            "\n",
            "         [[ 0.0097, -0.6696, -0.6720, -0.4932, -0.1854],\n",
            "          [-0.0669, -0.7029, -0.9482, -0.7607, -0.2206],\n",
            "          [ 0.0420, -0.5191, -0.6105, -0.6017, -0.0193],\n",
            "          [ 0.1494,  0.0206, -0.1589, -0.1527,  0.0931],\n",
            "          [ 0.1034, -0.0571,  0.0863, -0.1392,  0.1500]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2012, -0.0301,  0.0094, -0.0194, -0.0209],\n",
            "          [-0.0581, -0.0612,  0.0088,  0.0265, -0.1506],\n",
            "          [-0.0387, -0.0621,  0.1380,  0.0651, -0.1650],\n",
            "          [ 0.1125, -0.1252,  0.0420, -0.0906,  0.0473],\n",
            "          [ 0.0686,  0.0624,  0.0715, -0.0323,  0.0999]],\n",
            "\n",
            "         [[ 0.5120,  0.0913, -0.2652, -0.2569, -0.1163],\n",
            "          [ 0.3755,  0.1913,  0.0939, -0.2490, -0.0306],\n",
            "          [-0.0510,  0.0819,  0.3352, -0.3241, -0.0023],\n",
            "          [-0.0587, -0.1167,  0.2815, -0.2792, -0.4250],\n",
            "          [ 0.2092, -0.1653, -0.1405, -0.2353, -0.5883]],\n",
            "\n",
            "         [[ 0.4195, -0.0883, -0.3516, -0.0942,  0.0877],\n",
            "          [-0.0067,  0.0966, -0.2315, -0.0840,  0.1283],\n",
            "          [-0.2904, -0.0674, -0.0323, -0.1892,  0.1285],\n",
            "          [ 0.3181, -0.2888,  0.0193, -0.0408, -0.2070],\n",
            "          [ 0.2804,  0.0670,  0.1067,  0.1758,  0.2532]],\n",
            "\n",
            "         [[ 0.0256, -0.1428, -0.0686,  0.2498,  0.2347],\n",
            "          [ 0.0048, -0.2956, -0.1469,  0.1652,  0.3962],\n",
            "          [-0.1395, -0.1727, -0.2933,  0.0422,  0.0937],\n",
            "          [-0.2417, -0.0994, -0.1428, -0.1516,  0.0712],\n",
            "          [-0.0312, -0.1584, -0.1046, -0.0302,  0.0418]],\n",
            "\n",
            "         [[ 0.4672,  0.0442, -0.4182, -0.5051, -0.4100],\n",
            "          [ 0.6442,  0.1833, -0.1979, -0.5219, -0.4327],\n",
            "          [ 0.7698,  0.2583, -0.2513, -0.5211, -0.5869],\n",
            "          [ 0.5972,  0.2347, -0.1434, -0.4048, -0.6509],\n",
            "          [ 0.6145,  0.4353,  0.0246, -0.2509, -0.6439]],\n",
            "\n",
            "         [[-0.0304, -0.2370, -0.2660, -0.3402, -0.1382],\n",
            "          [ 0.1833, -0.0979, -0.0159, -0.1995, -0.3124],\n",
            "          [-0.0557,  0.0020, -0.0968,  0.0950, -0.1386],\n",
            "          [-0.0034,  0.0832, -0.0263, -0.0145, -0.0694],\n",
            "          [ 0.1066,  0.1285,  0.1692,  0.1117,  0.1465]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "torch.Size([16])\n",
            "Parameter containing:\n",
            "tensor([-0.1562,  0.4378, -0.1778, -0.1744, -0.7861,  1.0219, -1.5551,  1.1715,\n",
            "        -0.4155, -1.0800,  0.4286, -0.2228,  2.0972, -0.7946,  0.7695, -0.0658],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "torch.Size([120, 400])\n",
            "Parameter containing:\n",
            "tensor([[-0.0197, -0.0330, -0.0062,  ..., -0.0385, -0.1282, -0.1511],\n",
            "        [-0.0959, -0.1729, -0.0827,  ...,  0.0131, -0.0018, -0.0403],\n",
            "        [-0.1477, -0.0236,  0.0067,  ...,  0.0893,  0.0933, -0.0799],\n",
            "        ...,\n",
            "        [-0.1085, -0.0620, -0.0031,  ..., -0.0214, -0.1712, -0.0326],\n",
            "        [ 0.0774,  0.2078,  0.1502,  ...,  0.0941, -0.0321,  0.0131],\n",
            "        [ 0.0044, -0.0975, -0.0196,  ..., -0.2259, -0.0914, -0.0259]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "torch.Size([120])\n",
            "Parameter containing:\n",
            "tensor([ 0.1430, -0.0208, -0.0931,  0.4154, -0.0010, -0.0328, -0.0225,  0.0545,\n",
            "        -0.1247,  0.1002, -0.0306, -0.0334,  0.3293,  0.0263,  0.0847,  0.1347,\n",
            "         0.0020,  0.1505, -0.3322, -0.0339,  0.1825, -0.0376, -0.0037,  0.2443,\n",
            "         0.1639,  0.0056,  0.1680, -0.0319, -0.0347,  0.2144, -0.0269,  0.0728,\n",
            "         0.3503,  0.0768,  0.0924,  0.1803,  0.0191, -0.0601, -0.0089,  0.0481,\n",
            "        -0.0526, -0.0910,  0.1318,  0.1885, -0.2415, -0.0490, -0.0112, -0.0629,\n",
            "         0.1767, -0.0535,  0.1923, -0.0163,  0.0366, -0.1783,  0.0252, -0.0178,\n",
            "        -0.0174, -0.0394,  0.0053,  0.0507,  0.1912, -0.0419,  0.0188,  0.0917,\n",
            "         0.1810, -0.0010,  0.1620,  0.0876,  0.2509, -0.0692,  0.1068, -0.0546,\n",
            "        -0.1142, -0.0706, -0.0865,  0.2462,  0.1491,  0.0988,  0.2116,  0.0426,\n",
            "         0.4003,  0.1185,  0.0067, -0.1009, -0.1031, -0.0531,  0.0911, -0.0705,\n",
            "        -0.3245, -0.0628,  0.0482,  0.3976, -0.0238,  0.0466,  0.0150, -0.1253,\n",
            "         0.1823, -0.1068,  0.1771, -0.0502, -0.0240, -0.0497,  0.0640,  0.2373,\n",
            "         0.0089,  0.2727,  0.0179, -0.0339,  0.1944,  0.2082, -0.0152,  0.3989,\n",
            "        -0.0243, -0.0145, -0.0524, -0.4068,  0.2917, -0.1247, -0.0758,  0.1713],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "torch.Size([84, 120])\n",
            "Parameter containing:\n",
            "tensor([[ 0.1237, -0.0131,  0.0373,  ..., -0.0114,  0.0259, -0.0682],\n",
            "        [-0.1118, -0.0969, -0.1188,  ...,  0.0100, -0.0841, -0.1642],\n",
            "        [-0.0639, -0.1130, -0.1440,  ...,  0.0447, -0.0361,  0.0615],\n",
            "        ...,\n",
            "        [ 0.0401, -0.0348, -0.0471,  ..., -0.1711,  0.0129,  0.1095],\n",
            "        [-0.0337,  0.0118,  0.0429,  ..., -0.1061,  0.0188,  0.0248],\n",
            "        [-0.0778, -0.1887,  0.0700,  ..., -0.0582, -0.0641, -0.0230]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "torch.Size([84])\n",
            "Parameter containing:\n",
            "tensor([-0.1325,  0.4097, -0.1237,  0.2164, -0.0952,  0.7035,  0.3576,  0.1649,\n",
            "         0.3667, -0.1189, -0.1040, -0.0181,  0.5332,  0.4646, -0.0644,  0.2734,\n",
            "         0.0171,  0.4303,  0.0308,  0.1486,  0.2166,  0.1997,  0.4171,  0.1353,\n",
            "        -0.0767,  0.4373,  0.1043,  0.1594, -0.2036,  0.4209,  0.0152,  0.1855,\n",
            "        -0.0027,  0.1308,  0.3098,  0.3608,  0.0078,  0.1131,  0.1038,  0.0855,\n",
            "         0.1491, -0.0432,  0.2145, -0.0601,  0.8235, -0.0757,  0.4069, -0.0016,\n",
            "        -0.1098, -0.0732, -0.0245,  0.0691,  0.0938,  0.1906, -0.0473,  0.5084,\n",
            "         0.1609,  0.2486, -0.1249,  0.4322,  0.0241,  1.0116, -0.2080,  0.3922,\n",
            "         0.0832,  0.5009,  0.3642,  0.4821, -0.0255,  0.5043,  0.7220,  0.0158,\n",
            "         0.3204, -0.0846, -0.0050,  0.5433,  0.2652, -0.0502,  0.3402,  0.3772,\n",
            "         0.3459,  0.0601, -0.0440,  0.3693], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "torch.Size([10, 84])\n",
            "Parameter containing:\n",
            "tensor([[ 1.1583e-01, -1.8097e-02, -8.4390e-02,  9.1298e-02, -4.3799e-03,\n",
            "         -2.1476e-01,  2.3058e-02,  7.3129e-02,  1.8557e-01,  7.7777e-03,\n",
            "          9.4735e-03, -1.7988e-01,  1.4770e-01,  1.3531e-01, -1.2900e-01,\n",
            "         -2.6763e-01,  1.5364e-01,  1.9583e-01, -8.2691e-02,  9.1014e-02,\n",
            "          2.3392e-01,  3.2636e-01, -3.3397e-02,  2.6563e-01, -1.6755e-02,\n",
            "          2.8787e-01, -1.4314e-02,  1.6839e-01,  3.0166e-01, -1.0244e-01,\n",
            "          2.4134e-01,  1.6136e-01, -7.9805e-02, -1.9155e-03,  4.3738e-01,\n",
            "         -6.2639e-02, -5.8289e-04,  2.3302e-01,  2.7156e-01,  1.8384e-01,\n",
            "          8.0527e-02,  1.9477e-01, -1.9082e-01,  1.2922e-01,  7.1091e-03,\n",
            "          2.6122e-01,  2.5599e-01, -1.2061e-01,  2.8866e-02, -6.5772e-02,\n",
            "         -8.5824e-02, -1.0374e-01,  5.7271e-02,  1.6149e-01, -9.0116e-02,\n",
            "          7.0555e-02,  9.0718e-03,  2.2177e-01, -7.1456e-02,  1.5683e-02,\n",
            "         -5.6131e-02, -2.1209e-01,  3.0393e-01,  1.7903e-01,  4.7078e-02,\n",
            "          3.3958e-01,  1.3528e-01,  2.3523e-01,  6.1092e-02,  3.6152e-01,\n",
            "          1.0009e-01,  1.2279e-01,  2.1643e-01,  2.0696e-01,  2.1851e-01,\n",
            "         -7.4386e-02, -1.1196e-02, -4.8939e-02,  1.6660e-01, -5.0733e-02,\n",
            "         -1.3546e-01,  2.4889e-01,  1.9604e-01,  1.1793e-01],\n",
            "        [ 1.5201e-02,  1.1226e-01,  6.6431e-03, -1.4542e-01, -3.8493e-02,\n",
            "          1.6179e-01, -1.4545e-01,  1.2984e-01, -1.7679e-02,  1.1914e-01,\n",
            "          4.6420e-01, -1.1145e-01,  1.0729e-01, -9.1864e-02,  2.9212e-01,\n",
            "         -1.0635e-01,  3.0310e-01, -1.7094e-01,  2.7591e-01,  3.7361e-02,\n",
            "         -1.9657e-01, -3.0410e-02, -1.8359e-02,  8.2623e-02,  2.2408e-01,\n",
            "         -1.0952e-01, -4.8307e-02,  3.8302e-02,  1.3795e-01, -5.2267e-02,\n",
            "          1.5966e-03,  2.4517e-01, -1.1435e-02, -1.4874e-01,  3.2938e-01,\n",
            "         -3.4968e-02,  1.1438e-01, -8.5283e-04,  1.9706e-01,  6.5908e-02,\n",
            "          3.0225e-01, -1.0474e-02,  2.3482e-01,  9.3346e-02, -3.6809e-02,\n",
            "         -5.5946e-02, -2.6485e-01,  2.0895e-01, -3.4766e-02,  2.5310e-01,\n",
            "          6.3734e-03,  2.8571e-01,  3.2761e-01,  4.3865e-01, -8.1768e-02,\n",
            "          1.5290e-01,  9.4967e-05, -1.0545e-01,  5.0874e-03,  2.2137e-01,\n",
            "         -1.4401e-01, -8.7438e-02,  4.2158e-01, -3.5564e-02,  1.5604e-01,\n",
            "          6.4997e-02, -1.5821e-01, -2.3553e-01,  1.2787e-01,  4.2962e-01,\n",
            "         -3.5967e-02,  2.3580e-01,  7.9988e-02, -2.4024e-02,  2.4586e-01,\n",
            "         -1.4513e-01,  2.6628e-02,  7.6095e-02,  2.2680e-01,  2.3370e-01,\n",
            "         -3.8829e-02, -1.8973e-01,  6.0221e-02,  2.9287e-01],\n",
            "        [ 2.8991e-02, -2.0657e-03,  9.7041e-02,  2.8791e-01,  3.3935e-01,\n",
            "          2.0278e-01,  8.0108e-02,  2.6651e-01,  6.9259e-02,  1.0652e-01,\n",
            "         -1.6955e-02,  1.8225e-01,  3.0261e-02,  8.4693e-02, -8.4394e-02,\n",
            "          1.0810e-02,  8.9062e-02,  2.2063e-01,  8.8960e-02, -5.0765e-02,\n",
            "          3.1602e-01,  2.1184e-01,  1.8978e-01,  2.3164e-01, -3.1230e-02,\n",
            "          9.1248e-02,  1.4652e-01,  3.1747e-01,  2.7784e-01,  2.7694e-01,\n",
            "          1.6186e-01,  2.9650e-01, -8.0242e-02, -7.8209e-02,  1.2336e-01,\n",
            "          2.1667e-01,  5.5183e-02,  9.0871e-02, -1.8703e-01,  2.7803e-01,\n",
            "          1.7604e-01, -1.2224e-01,  5.9733e-02, -2.4198e-01,  3.9351e-01,\n",
            "          2.0461e-01,  2.3696e-01, -5.5237e-03,  6.7116e-02, -1.4741e-02,\n",
            "          1.5514e-01,  3.4685e-02,  3.0517e-01,  2.1870e-02,  1.2961e-01,\n",
            "          5.7780e-02,  1.8955e-01,  3.1105e-01,  8.1688e-02,  6.6464e-02,\n",
            "         -1.4904e-01,  3.7017e-01,  1.3446e-01, -1.0768e-01, -1.5054e-01,\n",
            "          1.1295e-02, -1.2654e-01,  7.8596e-02, -2.9830e-05,  9.7252e-02,\n",
            "          1.0392e-03,  6.1553e-02,  1.0041e-01, -4.5313e-02, -3.7201e-01,\n",
            "          3.5752e-01,  1.1658e-01,  1.0404e-01, -5.2436e-02,  2.6455e-01,\n",
            "         -1.3509e-02,  1.1712e-01,  8.7634e-04, -2.2925e-01],\n",
            "        [-4.8174e-02,  1.0313e-01,  2.2693e-01,  9.4652e-02, -1.6775e-02,\n",
            "          4.2599e-01,  1.0752e-01,  1.8142e-01,  7.9473e-03, -1.8336e-01,\n",
            "          5.5217e-02,  1.5745e-02,  2.8460e-01,  2.3493e-01, -6.3192e-03,\n",
            "          2.3414e-01,  9.9678e-02, -4.2324e-02,  2.3823e-01,  4.7877e-02,\n",
            "          2.0545e-01,  3.6555e-01,  2.7340e-01, -1.9352e-01,  4.4312e-02,\n",
            "          2.7030e-01, -6.5341e-03,  7.2249e-02,  1.4660e-01, -6.0093e-02,\n",
            "         -6.3493e-02,  1.9228e-01, -1.2117e-01,  7.0865e-02,  4.0241e-02,\n",
            "          2.9866e-02, -8.3799e-03, -7.9089e-02, -2.5879e-03, -2.7277e-02,\n",
            "          7.8334e-02, -1.8969e-01, -1.3721e-01, -1.8028e-01,  1.2417e-01,\n",
            "          5.8318e-02,  3.5655e-01,  4.9913e-03, -1.5609e-01, -7.6154e-02,\n",
            "         -5.3696e-02, -1.5244e-01,  1.7975e-01,  1.9023e-02, -7.6929e-02,\n",
            "         -8.4081e-02,  1.0876e-01,  2.6548e-01,  1.2663e-01,  3.0984e-01,\n",
            "          1.3530e-01,  4.7792e-01, -1.7220e-01,  1.7046e-01,  6.5647e-02,\n",
            "         -1.0312e-01,  1.2197e-01,  7.0229e-02,  9.0137e-02,  8.0660e-03,\n",
            "          2.4615e-01, -6.1480e-02,  2.7719e-01,  3.7226e-02,  6.6309e-03,\n",
            "          3.5086e-01, -9.9817e-02,  1.9804e-02,  8.6892e-02,  3.6450e-01,\n",
            "          1.9083e-01,  4.2220e-02, -8.5953e-02,  3.0846e-01],\n",
            "        [-1.0839e-01,  5.5394e-02,  4.9320e-02,  7.6473e-02, -1.1856e-01,\n",
            "          2.2850e-01, -1.9286e-01, -3.8060e-02,  2.7319e-01, -3.9275e-02,\n",
            "         -1.4411e-01,  1.6382e-01, -2.2257e-02, -2.8138e-02, -1.2493e-01,\n",
            "          6.3030e-02, -7.5671e-02,  3.3279e-01,  2.9244e-02,  4.3110e-03,\n",
            "          2.4271e-02,  5.1515e-02,  2.0612e-02, -1.5016e-03, -9.4900e-02,\n",
            "         -1.6666e-01,  2.8587e-02,  9.5705e-02, -1.4488e-01,  2.6626e-01,\n",
            "          1.1112e-01,  2.1319e-01, -1.2919e-01,  1.2541e-01, -9.2749e-02,\n",
            "          2.3922e-01, -7.6293e-02, -1.9070e-01,  6.4731e-02, -4.2993e-02,\n",
            "          1.9504e-04,  3.9602e-02,  2.0325e-01, -1.3708e-01,  3.2952e-01,\n",
            "         -1.3227e-02,  3.9890e-01, -1.2269e-01,  2.0539e-02, -1.2540e-01,\n",
            "         -2.5909e-01,  1.2126e-01,  8.8236e-02, -1.7428e-01,  2.4466e-02,\n",
            "          2.7223e-01,  1.0612e-01,  3.0486e-01, -7.5020e-02,  3.0262e-01,\n",
            "          1.7179e-01,  5.3990e-01, -9.6350e-02,  3.0569e-01, -2.2547e-02,\n",
            "          1.3590e-01,  8.7783e-02,  2.7006e-01, -1.7995e-02,  3.9289e-01,\n",
            "          3.1578e-01, -1.8387e-01,  1.7461e-01,  9.0641e-02,  2.4082e-03,\n",
            "          2.4996e-01,  3.7527e-01,  2.1870e-01, -5.6410e-02,  2.2075e-02,\n",
            "          1.9845e-01, -2.1153e-01, -4.6150e-02, -2.9167e-02],\n",
            "        [ 2.4932e-02,  3.1874e-01,  9.9414e-02, -6.2542e-02, -2.6439e-02,\n",
            "          4.4341e-01,  7.9038e-02,  1.4733e-01,  1.5953e-02, -5.9701e-02,\n",
            "         -7.4777e-02, -1.2490e-02,  2.0698e-01,  3.2489e-01,  5.8940e-03,\n",
            "          1.9568e-01,  2.0393e-01,  6.7898e-02, -1.5145e-01,  2.6025e-01,\n",
            "          4.4454e-02,  3.2408e-01,  2.6990e-02, -1.8035e-01,  3.4572e-03,\n",
            "          3.1221e-01,  1.9790e-01,  8.4054e-02,  5.3402e-02,  2.8876e-02,\n",
            "          2.6663e-02,  3.8069e-01, -1.0678e-01, -7.3083e-02, -1.4507e-01,\n",
            "         -1.6394e-01, -1.1574e-01,  2.6965e-02, -8.5145e-02, -8.2439e-02,\n",
            "         -3.4786e-02, -2.6214e-03,  7.5395e-02,  9.2238e-02,  2.9627e-01,\n",
            "          2.2716e-02,  4.5239e-01,  8.0149e-02, -2.7645e-02,  2.2298e-01,\n",
            "          1.1383e-01,  5.3046e-02,  2.6083e-01, -1.5080e-02,  5.4894e-02,\n",
            "         -1.1082e-01,  1.0357e-01,  2.2420e-01, -1.5971e-03,  3.3434e-01,\n",
            "          1.5538e-01,  4.2136e-01, -3.9051e-02,  1.1382e-01,  7.5198e-02,\n",
            "         -4.3223e-02, -1.0130e-01,  1.1385e-02,  3.8156e-02, -2.0184e-01,\n",
            "          3.2809e-01, -6.7887e-02,  6.5565e-02, -1.2667e-01, -1.5675e-02,\n",
            "          4.0963e-01,  1.1486e-01,  5.4226e-02,  2.4847e-03,  3.4992e-01,\n",
            "          2.1752e-01, -7.9873e-02, -1.0277e-01,  2.3280e-01],\n",
            "        [ 6.8776e-02,  3.0013e-01, -8.3309e-02,  7.3954e-02, -1.9925e-01,\n",
            "          4.1867e-01,  2.7021e-01,  3.6106e-01,  1.8643e-01, -9.6959e-02,\n",
            "         -3.0130e-02,  6.9329e-02,  2.6885e-02, -1.7669e-01, -8.5332e-02,\n",
            "         -6.6490e-02,  9.7767e-03, -1.4132e-01, -3.9933e-02,  1.0476e-02,\n",
            "          2.3668e-02,  8.1253e-02,  2.9611e-01, -6.4448e-02, -6.2023e-02,\n",
            "          1.1531e-01, -5.5438e-02,  3.2608e-01, -1.6543e-01,  2.8615e-01,\n",
            "          1.7655e-02, -2.2001e-01, -9.0917e-02,  7.7735e-02,  1.2279e-01,\n",
            "          5.1624e-02,  5.5999e-02,  1.1552e-02, -1.4386e-01,  1.1642e-01,\n",
            "          3.3926e-01,  1.3382e-01,  2.2131e-01,  8.7629e-02,  3.8385e-01,\n",
            "         -2.4592e-02,  3.3978e-01,  8.8440e-02,  4.8798e-02, -1.2596e-01,\n",
            "         -3.1076e-02,  4.6346e-02, -4.8721e-02,  2.0043e-02, -6.2664e-02,\n",
            "          2.5081e-01, -2.7063e-01, -1.5009e-01, -1.2873e-02,  1.8964e-02,\n",
            "         -1.5182e-01,  4.6407e-01, -5.8419e-02,  1.8526e-03,  1.1994e-01,\n",
            "         -1.5689e-01,  2.6467e-01,  1.5453e-01, -1.7356e-01, -1.6086e-01,\n",
            "          3.5840e-01,  1.5266e-01, -8.0540e-02,  2.2562e-02,  1.0988e-01,\n",
            "          2.8740e-01, -1.9901e-01, -1.7473e-01,  3.4487e-01,  4.6738e-01,\n",
            "         -1.5726e-01,  1.8974e-01,  1.1700e-01,  1.6821e-01],\n",
            "        [ 9.5157e-02, -3.7105e-02,  3.1278e-03,  2.4602e-02, -7.1138e-02,\n",
            "          2.3685e-01,  1.3828e-01, -1.2899e-01, -7.4179e-02,  1.0366e-02,\n",
            "         -4.1702e-02,  2.0985e-01,  4.0840e-02,  1.3144e-01,  8.4246e-02,\n",
            "          1.6554e-01,  3.2903e-01,  1.9918e-01, -7.1565e-03,  1.3713e-02,\n",
            "          3.4585e-01,  1.7332e-01, -2.1846e-01, -1.4249e-01, -2.5023e-02,\n",
            "          2.6377e-01, -1.3720e-01,  1.8309e-01,  7.9819e-02,  7.0525e-02,\n",
            "          7.1434e-02,  4.4574e-01,  1.5227e-01,  4.4201e-02,  2.2094e-01,\n",
            "         -3.0610e-02,  2.0076e-01, -1.4250e-01,  1.6920e-01, -3.1158e-01,\n",
            "         -1.0138e-01,  2.0819e-01,  2.8239e-01,  8.1844e-02,  7.9967e-02,\n",
            "         -4.5430e-02,  5.9267e-01, -2.2655e-01, -2.2797e-02, -2.6611e-02,\n",
            "          1.0785e-01, -1.2518e-01,  1.4833e-01, -3.5498e-02,  4.6759e-02,\n",
            "          4.3688e-02,  1.5408e-01,  1.4187e-01,  4.9007e-02,  1.8320e-02,\n",
            "          4.1561e-02,  4.4805e-01, -2.6539e-02,  2.5248e-01, -2.9401e-01,\n",
            "         -1.0924e-01, -4.9941e-02, -1.4978e-01,  3.9955e-01, -6.1085e-02,\n",
            "         -9.9358e-03,  9.3941e-02,  9.3324e-02, -1.4018e-01,  2.3810e-02,\n",
            "          3.1260e-01,  4.1230e-01, -1.5738e-01, -2.2473e-01,  3.8479e-01,\n",
            "          2.8551e-01, -8.7933e-02,  5.7439e-02,  1.6649e-01],\n",
            "        [-7.9954e-02, -1.4614e-01, -1.1842e-01,  1.9550e-01, -7.4962e-02,\n",
            "         -8.8162e-02,  3.0494e-01,  4.1380e-02,  1.5086e-01,  7.9942e-02,\n",
            "          1.7448e-01,  1.1459e-02,  2.6878e-01,  3.2810e-01, -7.7215e-02,\n",
            "          2.0042e-01, -1.7334e-01,  2.3941e-01,  2.3112e-01,  8.2000e-02,\n",
            "         -1.2087e-01,  3.4915e-02,  1.0984e-01,  1.9890e-01, -1.7825e-01,\n",
            "          1.4494e-01,  1.4242e-01, -1.4015e-01,  2.1606e-01, -4.6211e-02,\n",
            "         -1.8165e-01,  3.6226e-02,  1.5500e-01,  1.8796e-01,  4.5502e-01,\n",
            "         -6.6927e-03, -4.8585e-02,  2.8712e-01, -5.1947e-02,  8.9639e-02,\n",
            "          1.5878e-02, -2.2612e-01, -8.8288e-02,  3.3971e-02,  2.4635e-01,\n",
            "          7.3208e-03, -6.9890e-02,  3.4822e-03,  8.5346e-02, -8.9083e-02,\n",
            "         -5.6978e-02,  2.2064e-01, -9.3098e-02,  3.3514e-01, -9.2079e-02,\n",
            "         -5.9543e-02,  2.1194e-01, -6.2725e-02,  7.4865e-02, -4.2203e-02,\n",
            "          1.0196e-01, -3.8726e-01,  7.9036e-02, -2.6223e-01,  1.3167e-01,\n",
            "          3.0078e-01,  2.6839e-01,  2.1612e-01,  4.9734e-02,  4.6155e-01,\n",
            "         -1.0510e-01,  1.8869e-01, -3.8675e-02, -1.5337e-01, -9.2819e-03,\n",
            "         -3.0035e-01, -1.5314e-01, -1.3832e-01,  3.2859e-01, -4.2445e-02,\n",
            "          1.1855e-01, -3.2877e-02, -1.1137e-01, -1.7622e-01],\n",
            "        [-4.5150e-02,  2.5411e-01, -9.8162e-02, -1.2475e-01, -3.5933e-02,\n",
            "         -6.2405e-02,  7.6495e-02,  4.5012e-02, -1.6130e-01,  2.4340e-01,\n",
            "          2.1493e-01, -1.8774e-01, -3.8936e-02,  6.6252e-02,  7.1432e-02,\n",
            "          1.1778e-01,  3.4612e-01, -4.4941e-02,  1.6994e-01,  6.9971e-02,\n",
            "          2.7859e-01, -9.8800e-02,  1.4530e-01,  2.0203e-02,  3.8661e-02,\n",
            "          1.7339e-01, -3.3828e-02, -2.2445e-01,  2.9397e-02, -7.8505e-02,\n",
            "         -2.7163e-01,  6.7645e-03,  8.1689e-02,  9.0033e-02,  3.9899e-01,\n",
            "          1.3839e-01, -5.8271e-02,  9.5479e-02,  2.4905e-01,  1.8670e-01,\n",
            "          2.3695e-01,  1.8946e-01, -4.3759e-02,  1.2154e-01, -2.7529e-01,\n",
            "          1.0463e-02,  7.6311e-02, -4.6286e-02,  4.2289e-02,  9.1181e-02,\n",
            "          1.7897e-01,  2.3527e-01,  5.2049e-02,  3.1914e-01, -2.0268e-02,\n",
            "          1.5955e-01,  3.1096e-01, -6.6198e-02, -7.8127e-03,  1.1267e-01,\n",
            "         -3.8836e-02,  1.6035e-01,  3.0772e-01, -1.5332e-01,  2.8032e-01,\n",
            "          1.4490e-01,  1.6120e-01, -2.2284e-01,  7.5283e-02,  2.4730e-01,\n",
            "         -7.5844e-02,  1.9469e-02,  1.8326e-01, -5.3197e-02,  2.9035e-01,\n",
            "         -6.1704e-02, -6.4558e-03, -3.1431e-02, -2.9708e-02,  2.8008e-01,\n",
            "         -2.4577e-02,  6.7265e-02, -1.0751e-02,  2.9002e-01]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "torch.Size([10])\n",
            "Parameter containing:\n",
            "tensor([ 0.0521, -0.5109,  0.1923,  1.0233,  0.8805,  0.2783,  0.5020, -0.0088,\n",
            "         0.5893, -0.0063], device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBxsvClwTJiB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}