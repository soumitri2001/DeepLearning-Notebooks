# -*- coding: utf-8 -*-
"""Flower_Classification_Pytorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uUl5XO5GALphlsmXbTtu03K0i07gsNe9
"""

'''
Flower classification using PyTorch
dataset: https://www.kaggle.com/alxmamaev/flowers-recognition
'''

from google.colab import drive
drive.mount('/content/gdrive')

import os

os.environ['KAGGLE_CONFIG_DIR'] = "/content/gdrive/My Drive/Kaggle"

# Commented out IPython magic to ensure Python compatibility.
#changing the working directory
# %cd /content/gdrive/My Drive/Kaggle

# %pwd

!kaggle datasets download -d alxmamaev/flowers-recognition

#unzipping the zip files and deleting the zip files
!unzip \*.zip  && rm *.zip

DIR_PATH = '/content/gdrive/MyDrive/Kaggle/flowers/flowers'

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# pytorch imports

import torch
import torch.nn as nn
import torchvision
from torch.utils.data import Dataset,DataLoader
import torchvision.transforms as transforms
import torch.nn.functional as F

transformations = {
    'train': transforms.Compose([
        transforms.Resize(224),
        transforms.CenterCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ColorJitter(),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5]) # resnet18
    ]),
    'test': transforms.Compose([
        transforms.Resize(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5]) # resnet18
    ])
}

# hyperparamters

learning_rate = 0.01
batch_size = 32
num_epochs = 30
num_classes = 5

# device
device = None
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    device = torch.device('cpu')
    
print(device)

total_dataset = torchvision.datasets.ImageFolder(DIR_PATH,transform=transformations['train'])

len(total_dataset),total_dataset[0][0].shape,total_dataset.class_to_idx

# splitting into train and validation sets

SPLIT_SIZE = 0.8
tot_len = len(total_dataset)

train_size = int(SPLIT_SIZE * tot_len)
val_size = tot_len - train_size

print(f'Training set size = {train_size} \nValidation set size = {val_size}')

train_dataset, val_dataset =  torch.utils.data.random_split(total_dataset,[train_size,val_size])

len(train_dataset),len(val_dataset)

# dataloaders
train_loader = DataLoader(dataset=train_dataset,
                         batch_size=batch_size,
                         shuffle=True,
                         num_workers=4)

val_loader = DataLoader(dataset=val_dataset,
                       batch_size=batch_size,
                       shuffle=True,
                       num_workers=4)

# testing dataloading 

examples = iter(train_loader)
samples,labels = examples.next()
print(samples.shape,labels.shape) # batch_size=32
len(train_loader),len(val_loader)

# custom CNN model class

class ConvNet(nn.Module):
    def __init__(self,model,num_classes):
        super(ConvNet,self).__init__()
        self.base_model = nn.Sequential(*list(model.children())[:-1]) # model excluding last FC layer
        self.linear1 = nn.Linear(in_features=512,out_features=120)
        self.relu = nn.ReLU()
        self.linear2 = nn.Linear(in_features=120,out_features=num_classes)
    
    def forward(self,x):
        x = self.base_model(x)
        x = torch.flatten(x,1)
        lin = self.linear1(x)
        x = self.relu(lin)
        out = self.linear2(x)
        return lin, out

model = torchvision.models.resnet18(pretrained=True) # base model

model = ConvNet(model,num_classes)

model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)

print(model)

# training loop

n_iters = len(train_loader)

for epoch in range(num_epochs):
    model.train()
    for ii,(images,labels) in enumerate(train_loader):
        images = images.to(device)
        labels = labels.to(device)
        
        _,outputs = model(images)
        loss = criterion(outputs,labels)
        
        # free_gpu_cache()
        
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        
        if (ii+1)%25 == 0:
            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{ii+1}/{n_iters}], Loss = {loss.item():.6f}')
            
    print('----------------------------------------')

# evaluating model and getting features of every image
features = []

with torch.no_grad():
    # for entire test set
    n_correct = 0
    n_samples = 0

    # for each class label
    n_class_correct = [0 for i in range(num_classes)]
    n_class_samples = [0 for i in range(num_classes)]

    for images,labels in val_loader:

        images = images.to(device)
        labels = labels.to(device)

        ftrs,outputs = model(images)
        features.append(ftrs)

        _,preds = torch.max(outputs,1)
        n_samples += labels.size(0)
        n_correct += (preds == labels).sum().item()
            
    accuracy = n_correct/float(n_samples)

    print(f'Accuracy of model on test set = {(100.0 * accuracy):.4f} %')

ftrs = features.copy()

for i in range(len(ftrs)):
    ftrs[i] = ftrs[i].cpu().numpy()

ftrs = ftrs[:-1]

type(ftrs),ftrs[0].dtype,ftrs[0][0].dtype

ftrs = np.array(ftrs)
ftrs.shape

n_samples = ftrs.shape[0]*ftrs.shape[1]
n_features = ftrs.shape[2]
ftrs = ftrs.reshape(n_samples,n_features)
print(ftrs.shape)

# save to csv
ftrs_df = pd.DataFrame(ftrs)
ftrs_df.to_csv('./fc_layer_features.csv',index=False)

# reloading the saved csv into a df

ftrs_df = pd.read_csv('./fc_layer_features.csv')
ftrs_df

# save model
MODEL_PATH = 'flower_classification_model.pth'
torch.save(model.state_dict(),MODEL_PATH)

